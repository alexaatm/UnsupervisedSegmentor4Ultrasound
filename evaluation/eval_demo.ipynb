{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/oleksandra_tmenova/test/project/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from accelerate import Accelerator\n",
    "from matplotlib.cm import get_cmap\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from PIL import Image\n",
    "from skimage.color import label2rgb\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation utilities\n",
    "import eval_utils\n",
    "# for reading a dataset with groundth truth and labels\n",
    "from dataset import EvalDataset\n",
    "\n",
    "\n",
    "root_dir = 'demo_dataset'\n",
    "custom_dataset = EvalDataset(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add background class\n",
    "n_classes = 6\n",
    "n_clusters = 6\n",
    "\n",
    "# Iterate\n",
    "tp = [0] * n_classes\n",
    "fp = [0] * n_classes\n",
    "fn = [0] * n_classes\n",
    "\n",
    "# Load all pixel embeddings\n",
    "all_preds = np.zeros((len(custom_dataset) * 500 * 500), dtype=np.float32)\n",
    "all_gt = np.zeros((len(custom_dataset) * 500 * 500), dtype=np.float32)\n",
    "offset_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating all predictions: 100%|██████████| 1/1 [00:00<00:00, 108.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in trange(len(custom_dataset), desc='Concatenating all predictions'):\n",
    "    image, target, mask = custom_dataset[i]\n",
    "    # Check where ground-truth is valid and append valid pixels to the array\n",
    "    valid = (target != 255)\n",
    "    n_valid = np.sum(valid)\n",
    "    all_gt[offset_:offset_+n_valid] = target[valid]\n",
    "    # Append the predicted targets in the array\n",
    "    all_preds[offset_:offset_+n_valid, ] = mask[valid]\n",
    "    all_gt[offset_:offset_+n_valid, ] = target[valid]\n",
    "    # Update offset_\n",
    "    offset_ += n_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using hungarian algorithm for matching\n",
      "Using iou as metric\n",
      "Optimal matching: [(0, 5), (1, 1), (2, 0), (3, 2), (4, 3), (5, 4)]\n"
     ]
    }
   ],
   "source": [
    "# Truncate to the actual number of pixels\n",
    "all_preds = all_preds[:offset_, ]\n",
    "all_gt = all_gt[:offset_, ]\n",
    "\n",
    "# Do hungarian matching\n",
    "num_elems = offset_\n",
    "if n_clusters == n_classes:\n",
    "    print('Using hungarian algorithm for matching')\n",
    "    match = eval_utils.hungarian_match(all_preds, all_gt, preds_k=n_clusters, targets_k=n_classes, metric='iou')\n",
    "else:\n",
    "    print('Using majority voting for matching')\n",
    "    match = eval_utils.majority_vote(all_preds, all_gt, preds_k=n_clusters, targets_k=n_classes)\n",
    "print(f'Optimal matching: {match}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of semantic segmentation \n"
     ]
    }
   ],
   "source": [
    "# Remap predictions\n",
    "reordered_preds = np.zeros(num_elems, dtype=all_preds.dtype)\n",
    "for pred_i, target_i in match:\n",
    "    reordered_preds[all_preds == int(pred_i)] = int(target_i)\n",
    "\n",
    "# TP, FP, and FN evaluation\n",
    "for i_part in range(0, n_classes):\n",
    "    tmp_all_gt = (all_gt == i_part)\n",
    "    tmp_pred = (reordered_preds == i_part)\n",
    "    tp[i_part] += np.sum(tmp_all_gt & tmp_pred)\n",
    "    fp[i_part] += np.sum(~tmp_all_gt & tmp_pred)\n",
    "    fn[i_part] += np.sum(tmp_all_gt & ~tmp_pred)\n",
    "\n",
    "# Calculate Jaccard index\n",
    "jac = [0] * n_classes\n",
    "for i_part in range(0, n_classes):\n",
    "    jac[i_part] = float(tp[i_part]) / max(float(tp[i_part] + fp[i_part] + fn[i_part]), 1e-8)\n",
    "\n",
    "# Print results\n",
    "eval_result = dict()\n",
    "eval_result['jaccards_all_categs'] = jac\n",
    "eval_result['mIoU'] = np.mean(jac)\n",
    "print('Evaluation of semantic segmentation ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jaccards_all_categs': [0.0,\n",
       "  0.7693266832917706,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.46726946546892595],\n",
       " 'mIoU': 0.20609935812678273}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5), (1, 1), (2, 0), (3, 2), (4, 3), (5, 4)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
