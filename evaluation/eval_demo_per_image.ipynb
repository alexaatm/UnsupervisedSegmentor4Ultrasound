{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guests/oleksandra_tmenova/test/project/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from accelerate import Accelerator\n",
    "from matplotlib.cm import get_cmap\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from PIL import Image\n",
    "from skimage.color import label2rgb\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation utilities\n",
    "import eval_utils\n",
    "# for reading a dataset with groundth truth and labels\n",
    "from dataset import EvalDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: demo_gt\n",
      "image_dir: demo_gt/images\n",
      "gt_dir: demo_gt/ground_truth\n",
      "pred_dir: demo_gt/predictions\n",
      "Checking sizes of ground truth and predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 91.12it/s]\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'demo_gt'\n",
    "custom_dataset = EvalDataset(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes= 6\n",
      "n_clusters= 6\n"
     ]
    }
   ],
   "source": [
    "# Add background class\n",
    "n_classes = 6\n",
    "n_clusters = 6\n",
    "\n",
    "# Iterate\n",
    "tp = [0] * n_classes\n",
    "fp = [0] * n_classes\n",
    "fn = [0] * n_classes\n",
    "\n",
    "# metrics per image\n",
    "miou_all = []\n",
    "jac_all = []\n",
    "\n",
    "print('n_classes=', n_classes)\n",
    "print('n_clusters=', n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating predictions:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT unique labels: [0 1 2 3 4 5]\n",
      "PRED unique labels: [0 1 2 3 4 5]\n",
      "Using hungarian algorithm for matching\n",
      "Using iou as metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating predictions:  50%|█████     | 1/2 [00:00<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal matching: [(0, 0), (1, 3), (2, 5), (3, 1), (4, 2), (5, 4)]\n",
      "PER IMAGE: TP=[60590, 2946, 1824, 2404, 7519, 69814], FP=[464, 38, 481, 708, 3596, 4816], FN=[8094, 262, 0, 80, 114, 1553]\n",
      "PER DATASET: TP=[60590, 2946, 1824, 2404, 7519, 69814], FP=[464, 38, 481, 708, 3596, 4816], FN=[8094, 262, 0, 80, 114, 1553]\n",
      "PER IMAGE: jac_image_all_categs=[0.8762364782784752, 0.9075785582255084, 0.7913232104121475, 0.7531328320802005, 0.6696054857957076, 0.9163986716196527]\n",
      "GT unique labels: [0 1 4 5]\n",
      "PRED unique labels: [0 2 3 5]\n",
      "Using majority voting for matching\n",
      "No threshold used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating predictions: 100%|██████████| 2/2 [00:01<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal matching: [(0, 0), (3, 1), (0, 2), (0, 3), (5, 4), (2, 5)]\n",
      "PER IMAGE: TP=[0, 3513, 0, 0, 10192, 92322], FP=[0, 719, 0, 40908, 3235, 4311], FN=[48400, 7, 0, 0, 2, 764]\n",
      "PER DATASET: TP=[60590, 6459, 1824, 2404, 17711, 162136], FP=[464, 757, 481, 41616, 6831, 9127], FN=[56494, 269, 0, 80, 116, 2317]\n",
      "PER IMAGE: jac_image_all_categs=[0.0, 0.8287331917905166, 0.0, 0.0, 0.7589545014520813, 0.9478936722897009]\n",
      "MEAN of mIoU= 0.6208213834953326\n",
      "MEAN of mIoU from jac = 0.6208213834953326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in trange(len(custom_dataset), desc='Iterating predictions'):\n",
    "    image, gt, pred, metadata = custom_dataset[i]\n",
    "\n",
    "    # Do matching \n",
    "    gt_unique = np.unique(gt)\n",
    "    pred_unique = np.unique(pred)\n",
    "    print(f'GT unique labels: {gt_unique}')\n",
    "    print(f'PRED unique labels: {pred_unique}')\n",
    "    if np.array_equal(gt_unique,pred_unique) and n_clusters==n_classes:\n",
    "    # if len(gt_unique)==len(pred_unique):\n",
    "        print('Using hungarian algorithm for matching')\n",
    "        match, iou_mat  = eval_utils.hungarian_match(pred, gt, preds_k=n_clusters, targets_k=n_classes, metric='iou', thresh=0.0)\n",
    "    else:\n",
    "        print('Using majority voting for matching')\n",
    "        match, iou_mat = eval_utils.majority_vote_unique(pred, gt, preds_k=n_clusters, targets_k=n_classes, thresh=0.0)\n",
    "    print(f'Optimal matching: {match}')\n",
    "\n",
    "    # reorder prediction according to found mapping\n",
    "    reordered_pred = np.zeros_like(pred)\n",
    "    for pred_i, target_i in match:\n",
    "        reordered_pred[pred == int(pred_i)] = int(target_i)\n",
    "    \n",
    "    # calculate TP, FP, FN, TN for a single image - to get an IoU per image\n",
    "    tp_image = [0] * n_classes\n",
    "    fp_image = [0] * n_classes\n",
    "    fn_image = [0] * n_classes\n",
    "\n",
    "    # metrics per image\n",
    "    jac_image_all_categs = [0] * n_classes\n",
    "\n",
    "    # TP, FP, and FN evaluation, accumulated for ALL images\n",
    "    for i_part in range(0, n_classes):\n",
    "        tmp_gt = (gt == i_part) #get class i mask from ground truth\n",
    "        tmp_pred = (reordered_pred == i_part) #get class i mask from predictions\n",
    "        # just for the current image\n",
    "        tp_image[i_part] += np.sum(tmp_gt & tmp_pred)\n",
    "        fp_image[i_part] += np.sum(~tmp_gt & tmp_pred)\n",
    "        fn_image[i_part] += np.sum(tmp_gt & ~tmp_pred)\n",
    "        # accumulated for all\n",
    "        tp[i_part] += tp_image[i_part] \n",
    "        fp[i_part] += fp_image[i_part] \n",
    "        fn[i_part] += fn_image[i_part]\n",
    "\n",
    "        # calculate metrics per image\n",
    "        jac_image_all_categs[i_part] = float(tp_image[i_part]) / max(float(tp_image[i_part] + fp_image[i_part] + fn_image[i_part]), 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "    print(f'PER IMAGE: TP={tp_image}, FP={fp_image}, FN={fn_image}')\n",
    "    print(f'PER DATASET: TP={tp}, FP={fp}, FN={fn}')\n",
    "    print(f'PER IMAGE: jac_image_all_categs={jac_image_all_categs}')\n",
    "\n",
    "\n",
    "    miou_image = np.mean(jac_image_all_categs)\n",
    "    miou_all.append(miou_image)\n",
    "    jac_all.append(jac_image_all_categs)\n",
    "\n",
    "mIoU_mean = np.mean(miou_all)\n",
    "mIoU_std = np.std(miou_all)\n",
    "print('MEAN of mIoU=', mIoU_mean)\n",
    "\n",
    "mIoU_mean_from_jac = np.mean(np.mean(jac_all))\n",
    "print('MEAN of mIoU from jac =', mIoU_mean_from_jac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old mIoU1= 0.6460911940855601\n",
      "old mIoU2= 0.6208213834953323\n"
     ]
    }
   ],
   "source": [
    " # Calculate Jaccard index\n",
    "jac1 = [0] * n_classes\n",
    "jac2 = [0] * n_classes\n",
    "\n",
    "for i_part in range(0, n_classes):\n",
    "    jac1[i_part] = float(tp[i_part]) / max(float(tp[i_part] + fp[i_part] + fn[i_part]), 1e-8)\n",
    "    jac2[i_part] = np.mean(jac_all, axis=0)\n",
    "old_mIoU_mean1 = np.mean(jac1)\n",
    "old_mIoU_mean2 = np.mean(jac2)\n",
    "# old_mIoU_mean3 = np.mean(jac_new) / 2\n",
    "\n",
    "print('old mIoU1=', old_mIoU_mean1) # somehow is different from mIoU_mean\n",
    "print('old mIoU2=', old_mIoU_mean2) # somehow is same as mIoU_mean\n",
    "# print('old mIoU3=', old_mIoU_mean3) # somehow is different from mIoU_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8762364782784752,\n",
       "  0.9075785582255084,\n",
       "  0.7913232104121475,\n",
       "  0.7531328320802005,\n",
       "  0.6696054857957076,\n",
       "  0.9163986716196527],\n",
       " [0.0, 0.8287331917905166, 0.0, 0.0, 0.7589545014520813, 0.9478936722897009]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
